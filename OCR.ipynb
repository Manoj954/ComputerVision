{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import image_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src=\"D:\\\\Projects\\\\Mark\\\\OCR\\\\python-ocr-master\\\\python-ocr-master\\\\images\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start recognize text from image ---\n"
     ]
    }
   ],
   "source": [
    "print('--- Start recognize text from image ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Users\\\\M1046091\\\\AppData\\\\Local\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Projects\\\\Mark\\\\OCR\\\\python-ocr-master\\\\python-ocr-master\\\\images\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-da856e1787d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\condaOpenCV\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2547\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2548\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2549\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Projects\\\\Mark\\\\OCR\\\\python-ocr-master\\\\python-ocr-master\\\\images\\\\'"
     ]
    }
   ],
   "source": [
    "print (image_to_string(Image.open(src)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRAT TR]\n",
      "\n",
      "Oe Ts eg\n",
      "\n",
      " \n",
      "\n",
      ") human builds model based on input / output\n",
      "\n",
      "human input, machine output\n",
      "‘human utlizes if satistactory\n",
      "\n",
      "human input, machine output\n",
      "‘human reward/punish, cycle continues\n",
      "\n",
      "linear made! Linearftegression()\n",
      "\n",
      "Lots of numerical data As\n",
      "ie)\n",
      "\n",
      " \n",
      "\n",
      "linear_model.LogisticRegression()\n",
      "Target variable is categorical ¢\n",
      "\n",
      "LASSIFICATION\n",
      "opt:\n",
      "\n",
      "oe\n",
      "iis\n",
      "\n",
      "is\n",
      "\n",
      "oo\n",
      "\n",
      "| NAIVE BAYES\n",
      "\n",
      ") cluster KMeans0)\n",
      "‘Similar datum into groups\n",
      "based on contoids\n",
      "\n",
      "4 Etiptcalenvsloped)\n",
      "Finding outers\n",
      "\n",
      "fra oreral Ces) (es) ND fon)\n",
      "\n",
      "‘manifold. TSNEQ,\n",
      "\n",
      "cameramen,\n",
      "so D>\n",
      "sea\n",
      "\n",
      "Distil feature space into components that\n",
      "describe greatest variance\n",
      "\n",
      "decomposition COA\n",
      "\n",
      "Making sense of cross-correlation a\n",
      "\n",
      "‘matrices\n",
      "\n",
      "‘da.LDAQ,\n",
      "near combination of features that iA\n",
      "Separates classes\n",
      "\n",
      " \n",
      "\n",
      "(P+ TP +N)\n",
      "TPIT + FP)\n",
      "\n",
      "wires\n",
      "wires >|\n"
     ]
    }
   ],
   "source": [
    "print (image_to_string(Image.open(src), lang='eng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.0\n"
     ]
    }
   ],
   "source": [
    "print (cv2. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(major, minor, _) = cv2.__version__.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18900.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the example image and convert it to grayscale\n",
    "image = cv2.imread(src+\"3.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "preprocessingType=\"thresh\"\n",
    "# check to see if we should apply thresholding to preprocess the\n",
    "# image\n",
    "#gray = cv2.GaussianBlur(gray,(5,5),0)\n",
    "if preprocessingType == \"thresh\":\n",
    "    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    #gray=cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,3,2)[1]\n",
    "    #gray = cv2.threshold(gray,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    #print (1)\n",
    "# make a check to see if median blurring should be done to remove\n",
    "# noise\n",
    "elif preprocessingType == \"blur\":\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    " \n",
    "# write the grayscale image to disk as a temporary file so we can\n",
    "# apply OCR to it\n",
    "filename = \"{}.png\".format(os.getpid())\n",
    "print(filename)\n",
    "cv2.imwrite(filename, gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZAction\n",
      "\n",
      "Bseade\n",
      "\n",
      "shoulders\n",
      "\n",
      "{et scmuppan shamaoe\n",
      "shampooing anbpattictanrs\n",
      "\n",
      "at classic clean\n"
     ]
    }
   ],
   "source": [
    "# load the image as a PIL/Pillow image, apply OCR, and then delete\n",
    "# the temporary file\n",
    "text = pytesseract.image_to_string(Image.open(filename))\n",
    "os.remove(filename)\n",
    "print(text)\n",
    " \n",
    "# show the output images\n",
    "#cv2.imshow(\"Image\", image)\n",
    "#cv2.imshow(\"Output\", gray)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (condaOpenCV)",
   "language": "python",
   "name": "condaopencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
